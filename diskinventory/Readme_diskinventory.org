#+TODO: TODO NEXT WAITING | DONE CANCELED
#+TAGS: PROJECT(p)  READING(r) 
#+TYP_TODO: TODO MAYBE WAITING NEXT DONE
#+STARTUP: showall
#+STARTUP: hidestars

* Readme_diskinventory.org

* project design

  use scandir with [[file:~/repos/pythonlibs/pyutils/check_md5.py]]
  to calculate keys

  put fixed information in dataframe, path information in database

<2015-06-19 Fri>

* notes under repository control



* Disk inventory code


/etc/cron.daily/backup  on roc
/etc/cron.daily/rdiff_backups.sh on kite

1) Running ls and du to get file information

  ./read_cron.py tera /tera/phil/diskinventory/

  will produce read du_tera* and ls_tera* from 
  /backupspace/stats_newroc and produce 

  /tera/phil/diskinventory/files_tera_phil.db

contains two tables
direcs:    columnNames=['size','level','directory']
files:     columnNames=['permission','links','owner','theGroup','size','date','directory','name','hash']


python3 retrieve.py /tera/phil/diskinventory/files_tera.db phil


* DONE make di work with directory compare
  CLOSED: [2016-03-19 Sat 12:03]

** compare tera and pip as a test
   :PROPERTIES:
   :ELDORO_POMODORI: 7
   :END:

* workflow for recover code

0) Run the following cron job on roc:

/etc/cron.daily phil@newroc% cat rdiff_backups.sh
#!/bin/bash

#du -k /tera  > /backups/du_tera.txt
#du -k /tera2  > /backups/du_tera2.txt
du -k /users  > /backupspace/stats_newroc/roc_users.txt
ls -R -l -Q --time-style=full-iso --time=status /tera/ > /backupspace/stats_newroc/ls_tera.txt
du -k /tera/  > /backupspace/stats_newroc/du_tera.txt
ls -R -l -Q --time-style=full-iso --time=status /newtera/ > /backupspace/stats_newroc/ls_newtera.txt
du -k /newtera/  > /backupspace/stats_newroc/du_newtera.txt
ls -R -l -Q --time-style=full-iso --time=status /users/ > /backupspace/stats_newroc/ls_users.txt
du -k /users/  > /backupspace/stats_newroc/du_users.txt


on osx use:  gls and gdu from brew coreutils



1) use read_cron.py to read the files  [[file:read_cron.py][read_cron.py]]

python read_cron.py -r . di .


2) write a pandas dataframe out with

python big_table_write.py files_di.db files_di.h5

[[file:big_table_write.py::big_table_write][big_table_write.py]]

3) working example in [[file:small_test.sh::#%20small_test.sh][small_test.sh]]

4) recovery example in [[file:tera_recover.py::ipython%20console:%20run%20with%20%25run%20-i][tera_recover.py]]


* start over using

* work on du as rough indentifier

** on pip do du -k  write the file out to  [[file:/pip_raid/phil/tera/du_pip_raid.txt]]

** now read that in using [[file:read_cron.py][read_cron.py]]

** new code is in parse_files.py  

   python -m diskinventory.parse_files du_pip_raid.txt ls_pip_raid.txt pip_raid

* focus first on 

  /tera/phil/nchaparr/python phil@newroc% du -k Plotting > du_plotting.txt
  
  in newroc:/home/phil/dirtrial
  
* delete indvidual files from list  using diskinvetory.parsefiles

  - make_ls.py uses du and ls to create an h5 file with dataframes
  - read_ls_h5.py reads the h5 file
  - plotting.yaml contains the yaml config

* <2016-03-19 Sat>  do a census of vlads files

  working with [[file:/newtera/tera/phil/vlad_newtera.yaml::#%20vlad_newtera.yaml][vlad_newtera.yaml]]
  add up all cloud tracking files
  
* <2016-03-20 Sun>  
  get [[file:read_ls_h5.py::*%20read_ls_h5.py][read_ls_h5.py]] going
  run with python -m diskinventory.read_ls_h5 *h5
  reads the internal yaml file


* get all bin3d files moved to pip
  working in /newtera/tera/phil/diskinventory/
  symbolic link to ln -s ~/repos/pythonlibs/diskinventory/vlad_newtera.yaml .
    produces vlad_checkpoints_thin.h5

  python -m diskinventory.find_bin3d *thin*h5

  produces  filelist.txt 

/newtera/tera/vpopa/sam_checkpoints/CGILS_S6_IDEAL_GREX/OUT_3D/CGILS_S6_IDEAL_295K_3D_96x96x121_100m_100m_40m_1s_48_0000000300.bin3D
/newtera/tera/vpopa/sam_checkpoints/CGILS_S6_IDEAL_GREX/OUT_3D/CGILS_S6_IDEAL_295K_3D_96x96x121_100m_100m_40m_1s_48_0000000600.bin3D
/newtera/tera/vpopa/sam_checkpoints/CGILS_S6_IDEAL_GREX/OUT_3D/CGILS_S6_IDEAL_295K_3D_96x96x121_100m_100m_40m_1s_48_0000000900.bin3D
/



/media/sea8a/data phil@pip% rsync -av --files-from=filelist.txt newroc:/ .

check this filelist in as  history/vpop_2016_2_27




* here is the cronjob

/etc/cron.daily phil@newroc% cat backup
#!/bin/bash

#du -k /tera  > /backups/du_tera.txt
#du -k /tera2  > /backups/du_tera2.txt
du -k /users  > /backupspace/stats_newroc/roc_users.txt
ls -R -l -Q --time-style=full-iso --time=status /tera/ > /backupspace/stats_newroc/ls_tera.txt
du -k /tera/  > /backupspace/stats_newroc/du_tera.txt
ls -R -l -Q --time-style=full-iso --time=status /newtera/ > /backupspace/stats_newroc/ls_newtera.txt
du -k /newtera/  > /backupspace/stats_newroc/du_newtera.txt
ls -R -l -Q --time-style=full-iso --time=status /users/ > /backupspace/stats_newroc/ls_users.txt
du -k /users/  > /backupspace/stats_newroc/du_users.txt

#du -k /backups/kite  > /backups/kite_users.txt

#Backup script to perform rdiff-backups of select /users directories
users=(ccorbel\ hbarker\ jcole\ jdawe\ mjerg\ mshephar\ nchaparr\ user-soft\ loh\ austinp\ ecsim\ vpopa\ csioris\ ftornow\ cpatrizi\ phil)

for i in $users; do
    /usr/bin/rdiff-backup --force -v 6 /home/$i /backupspace/newroc_users/$i # >& /backupspace/logs/$i/backup.log
    #cat /backupspace/logs/$i/backup.log
    #chmod ugo+r /backupspace/logs/$i/backup.log
done

 /usr/bin/rdiff-backup --force -v 6 /newtera/safe /backupspace/newtera/safe 

<2017-05-11 Thu>

/repos/pythonlibs/diskinventory
python diskinventory/parse_files.py stats_newroc/du_users.txt stats_newroc/ls_users.txt users

in /Users/phil/repos/pythonlibs/diskinventory:
rsync --progress --stats -az -e ssh newroch:/backupspace/stats_newroc/ stats_newroc/.


python -m diskinventory.parse_files stats_newroc/du_users.txt stats_newroc/ls_users.txt users

run /home/phil/repos/pythonlibs/diskinventory/diskinventory/parse_files.py stats_newroc/du_users.txt stats_newroc/ls_users.txt users

python -m diskinventory.parse_files stats_newroc/du_users.txt stats_newroc/ls_users.txt users

python -m diskinventory.parse_files stats_newroc/du_tera.txt stats_newroc/ls_tera.txt tera

python -m diskinventory.parse_files stats_newroc/du_newtera.txt stats_newroc/ls_newtera.txt newtera

<2017-07-02 Sun>

parse_files.py produces a set of parque files

read_parque.py concatenates them into a single dask dataframe and writes to out_newtera

try to repartition with dask_process.py

try again with dask_reprocess.py

<2017-07-03 Mon>
